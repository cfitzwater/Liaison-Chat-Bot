# Project Design Document: Liaison Library Bot

## Section 1: Project Overview
**Project Title:** Liaison Library Bot (RAG-Enabled Clinical Assistant)  
**Application Purpose:** The Liaison Library Bot is a Retrieval-Augmented Generation (RAG) application designed to serve as an intelligent interface for the "The Real Liaison Team Chat" document repository. In healthcare liaison work, critical information is often buried in disparate PDFs, insurance grids, and SOPs. This application indexes those unstructured files into a vector database, allowing users to ask natural language questions and receive conversational answers grounded specifically in the department's approved documentation. This ensures "source-of-truth" accuracy while eliminating manual search time.

**Intended User:** Clinical Liaisons and Registered Nurse Liaisons who need immediate, cited access to facility protocols and insurance eligibility guidelines during the patient intake process.

## Section 2: Core Features
* **Document Ingestion & Chunking:** A Python pipeline that uses `data_ingestion.py` to parse PDFs and break them into contextual segments.
* **Vector Database (ChromaDB):** Uses a persistent local database to store text along with high-dimensional embeddings generated by the `all-MiniLM-L6-v2` transformer model.
* **AI-Powered Semantic Search:** Instead of keyword matching, the bot finds relevant documents based on the "meaning" of the user's query.
* **LLM Integration (Gemini Pro):** Leverages Google's Gemini API to synthesize retrieved documents into a professional, cited answer.



## Section 3: Data Model
The structure of a single **Document Chunk** record within the ChromaDB collection is defined as follows:

| Field Name | Data Type | Description |
| :--- | :--- | :--- |
| **ids** | UUID String | A unique identifier for the specific segment of text. |
| **documents** | Text | The actual string of text extracted from the document. |
| **embeddings** | List (Float) | The 384-dimensional numerical representation of the text. |
| **metadatas** | Dictionary | Stores `source` (filename) and `page` (page number) for citations. |

---

## Chunk 1: CLI Application Prototype
This section documents the functional prototype of the Liaison Library Bot, developed as a Command Line Interface (CLI) as per technical requirements.

### Prototype Requirements
* **Text-Based Menu:** A clear interface allowing users to navigate between adding documents, viewing data, searching, and exiting.
* **Continuous Loop:** The program remains active, re-displaying the menu after each action until the user chooses option 4 (Exit).
* **Modular Design:** Dedicated functions for `add_document()`, `display_all_chunks()`, and `search_documents()`.
* **Persistent Data Management:** While the script runs a loop, it utilizes **ChromaDB** for persistent storage, ensuring data remains available even after the program restarts.

### Technical Implementation
The current `app.py` script serves as the primary controller. It orchestrates the following flow:
1. **Embedding Generation:** Uses `SentenceTransformer` to convert raw text into a format the computer can "understand."
2. **Contextual Retrieval:** When searching, the top 5 most relevant chunks are retrieved from the vector store.
3. **Augmented Generation:** The retrieved chunks are passed into a strict prompt for **Gemini-Pro**, forcing the AI to only use the provided healthcare documentation to answer, ensuring clinical accuracy.

| Function | Requirement Covered |
| :--- | :--- |
| `main()` | Continuous Loop / Menu Logic |
| `add_document()` | Add new item functionality |
| `display_all_chunks()` | List all items functionality |
| `search_documents()` | Advanced RAG search & AI Generation |